{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS Lab: Network Structure\n",
    "This lab demonstrates how to use common tools to analyze the structure of several networks. Topics covered include visualization, centrality measures, shortest paths, and affiliation networks. At the end of the lab, you will be able to visualze and perform an analysis of your own social network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "2. [Build and visualize a network](#Build-and-visualize-a-network)\n",
    "    1. [Load the network](#Load-the-network)\n",
    "    2. [Visualize the network](#Visualize-the-network)\n",
    "3. [Centrality measures](#Centrality-measures)\n",
    "    1. [Find centrality](#Find-centrality)\n",
    "    2. [Interpret centrality](#Interpret-centrality)\n",
    "    3. [Compare centrality measures](#Compare-centrality-measures)\n",
    "4. [Paths](#Paths)\n",
    "    1. [Find path lengths](#Find-path-lengths)\n",
    "    2. [Bridges and weak ties](#Bridges-and-weak-ties)\n",
    "    3. [Find minimum cut](#Find-minimum-cut)\n",
    "5. [Affiliation networks](#Affiliation-networks)\n",
    "    1. [Weighted edges](#Weighted-edges)\n",
    "6. [Your social network](#Your-social-network)\n",
    "    1. [Visualize your social network](#Visualize-your-social-network)\n",
    "    2. [Social network communities](#Social-network-communities)\n",
    "    3. [Social network centrality](#Social-network-centrality)\n",
    "    4. [Find connected component](#Find-connected-component)\n",
    "    5. [Social network path lengths](#Social-network-path-lengths)\n",
    "    6. [Find bridges](#Find-bridges)\n",
    "7. [References](#References)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We import several libraries, including `networkx` for network algorithms, `pandas` for data processing, and `visJS2jupyter` for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import urllib.request\n",
    "import networkx as nx\n",
    "import networkx as networkx\n",
    "import networkx.algorithms as nxalg\n",
    "import networkx.algorithms.community as nxcom\n",
    "import networkx.readwrite as nxrw\n",
    "import pandas as pd\n",
    "import visJS2jupyter.visJS_module as vjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and visualize a network\n",
    "\n",
    "This section loads network data from a file and explores its basic properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_hamilton_affiliation():\n",
    "    B = nxrw.adjlist.read_adjlist(\"external/hamilton.csv\", delimiter=\"; \", comments=\"%\")\n",
    "    return B\n",
    "\n",
    "def load_hamilton(threshold=None):\n",
    "    # Load the song-character affiliation network\n",
    "    B = load_hamilton_affiliation()\n",
    "    # Get list of songs from the file\n",
    "    songs = set()\n",
    "    with open(\"external/hamilton.csv\") as f:\n",
    "        f.readline()\n",
    "        for row in f:\n",
    "            songs.add(row.split(\"; \")[0])\n",
    "    # Deduce list of charactes\n",
    "    characters = set(B.nodes()) - songs\n",
    "    # Project the affiliation network onto the set of characters\n",
    "    G = nxalg.bipartite.projection.weighted_projected_graph(B, characters)\n",
    "    # Threshold\n",
    "    if threshold is not None:\n",
    "        for s, t, data in list(G.edges(data=True)):\n",
    "            if data[\"weight\"] < threshold:\n",
    "                G.remove_edge(s,t)\n",
    "    return G\n",
    "\n",
    "def get_colors():\n",
    "    phi = (1 + math.sqrt(5)) / 2\n",
    "    color = []\n",
    "    for i in range(1, 20):\n",
    "        theta = phi * i * math.pi * 2\n",
    "        x = 128 + math.floor(64*math.sin(theta))\n",
    "        y = 128 + math.floor(64*math.cos(theta))\n",
    "        color.append((x, x, y))\n",
    "    return color\n",
    "\n",
    "def visualize_visjs(\n",
    "        G, communities=None, colors=None, default_color=\"192,192,192\",\n",
    "        node_size_field=\"node_size\", layout=\"spring\", scale=500, pos=None,\n",
    "        groups=None, weight=None, labels=dict(), title=\"\"):\n",
    "    # Get list of nodes and edges\n",
    "    nodes = list(G.nodes())\n",
    "    edges = list(G.edges())\n",
    "    # Change node shapes for bipartite graph\n",
    "    if groups is None:\n",
    "        node_shapes = dict()\n",
    "        node_sizes = dict()\n",
    "        node_colors = dict()\n",
    "    else:\n",
    "        node_shapes = dict((n, \"square\") for n in groups)\n",
    "        node_sizes = dict((n, 15) for n in groups)\n",
    "        node_colors = dict((n, \"192,128,0\") for n in groups)\n",
    "    # Per-node properties\n",
    "    nodes_dict = dict((n, {\n",
    "        \"id\": labels.get(n, n),\n",
    "        \"node_size\": node_sizes.get(n, 5),\n",
    "        \"node_shape\": node_shapes.get(n, \"dot\")\n",
    "        }) for n in nodes)\n",
    "    # Generate a layout for the nodes\n",
    "    edge_smooth_enabled = False\n",
    "    edge_width = 4\n",
    "    edge_arrow_scale = 2\n",
    "    if communities is not None and pos is None:\n",
    "        # Generate initial positions based on community\n",
    "        phi = 3.14 / len(nodes)\n",
    "        community_node = []\n",
    "        # Create list of nodes and their communities\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                community_node.append((i, node))\n",
    "        # Sort by community and\n",
    "        community_node = sorted(community_node)\n",
    "        # Generate initial position by placing communities around a circle\n",
    "        pos = dict((d[1], (math.cos(i*phi), math.sin(i*phi))) for i, d in enumerate(community_node))\n",
    "    else:\n",
    "        pos = None\n",
    "    if layout == \"circle\":\n",
    "        pos = nx.circular_layout(G, scale=scale)\n",
    "    elif layout == \"spring\":\n",
    "        pos = nx.spring_layout(G, k=3/math.sqrt(len(nodes)), scale=scale, pos=pos)\n",
    "    else:\n",
    "        edge_smooth_enabled = True\n",
    "    # Assign position\n",
    "    for n in nodes:\n",
    "        nodes_dict[n][\"x\"] = pos[n][0]\n",
    "        nodes_dict[n][\"y\"] = pos[n][1]\n",
    "    # Calculate bounds for scaling\n",
    "    x_min = min(pos.values(), key=lambda x: x[0])[0]\n",
    "    x_max = max(pos.values(), key=lambda x: x[0])[0]\n",
    "    y_min = min(pos.values(), key=lambda x: x[1])[1]\n",
    "    y_max = max(pos.values(), key=lambda x: x[1])[1]\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    max_range = max(x_range, y_range)\n",
    "    # If we have communities, assign color based on community\n",
    "    if colors is None:\n",
    "        colors = [\"{},{},{}\".format(*c) for c in get_colors()]\n",
    "    if communities is not None:\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                try:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},1)\".format(colors[i])\n",
    "                    nodes_dict[node][\"color_index\"] = i\n",
    "                except IndexError:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},1)\".format(default_color)\n",
    "    # Update color for bipartite nodes\n",
    "    for node, node_attr in nodes_dict.items():\n",
    "        if node in node_colors:\n",
    "            node_attr[\"color\"] = \"rgba({},1)\".format(node_colors[node])\n",
    "    # Map node labels to contiguous ids\n",
    "    node_map = dict(zip(nodes,range(len(nodes))))\n",
    "    # Determine edge colors\n",
    "    edge_colors_idx = {}\n",
    "    for source, target in edges:\n",
    "        source_color = nodes_dict[source].get(\"color_index\", None)\n",
    "        target_color = nodes_dict[target].get(\"color_index\", None)\n",
    "        if source_color == target_color and source_color is not None:\n",
    "            edge_colors_idx[(source, target)] = source_color\n",
    "    edge_colors = dict(\n",
    "        (e,colors[c])\n",
    "        for e, c in edge_colors_idx.items() if c < len(colors))\n",
    "    # Per-edge properties, use contiguous ids to identify nodes\n",
    "    edge_scale = math.ceil(max_range / 200)\n",
    "    edges_dict = []\n",
    "    for source, target, data in G.edges(data=True):\n",
    "        edge = {\n",
    "            \"source\": node_map[source],\n",
    "            \"target\": node_map[target],\n",
    "            \"title\":'test',\n",
    "            \"color\": \"rgba({},0.3)\".format(edge_colors.get((source,target), default_color)),\n",
    "            \"edge_width_field\": \"value\",\n",
    "            \"value\": data.get(\"value\", 1) * edge_scale\n",
    "        }\n",
    "        edges_dict.append(edge)\n",
    "    # Convert nodes dict to node list\n",
    "    nodes_list = [nodes_dict[n] for n in nodes]\n",
    "    # Check for directed graph\n",
    "    if G.__class__ == nx.classes.digraph.DiGraph:\n",
    "        directed = True\n",
    "    else:\n",
    "        directed = False\n",
    "    # Call visjs\n",
    "    return vjs.visjs_network(\n",
    "        nodes_list, edges_dict,\n",
    "        node_size_field=\"node_size\",\n",
    "        node_size_multiplier=10.0,\n",
    "        edge_width_field=\"value\",\n",
    "        edge_width=edge_width,\n",
    "        edge_arrow_to=directed,\n",
    "        edge_arrow_to_scale_factor=edge_arrow_scale,\n",
    "        edge_smooth_enabled=edge_smooth_enabled,\n",
    "        edge_smooth_type=\"curvedCW\",\n",
    "        graph_id=hash(title))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the network\n",
    "\n",
    "The next cell loads data from a file using the `networkx` library,\n",
    "and displays a list of nodes in the network.\n",
    "This example uses characters from the play _Hamilton_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_hamilton()\n",
    "sorted(G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the labels of the nodes, you can see which nodes are connected by an edge.\n",
    "In this case, two nodes are connected by an edge if the corresponding characters have parts in the same song.\n",
    "The next cell chooses a single node and prints a list of all the other nodes it's connected to.\n",
    "These nodes are called its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(G.neighbors('E. Schuyler'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the network\n",
    "In these visualizations, each circle represents a node.\n",
    "Edges between two nodes are represented by drawing a line between them.\n",
    "\n",
    "There are many ways to draw a network.\n",
    "One simple way is to space all the nodes evenly around a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_visjs(G, layout=\"circle\", title=\"Circular Layout Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common way to visualize a network is using a \"force-directed\" layout.\n",
    "In a force-directed layout, nodes push away from each other, but edges act like springs pulling them back together.\n",
    "As a result, nodes with many neighbors in common are pulled closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_visjs(G, scale=1000, title=\"Force-Directed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the people in the center of the network have in common? What about the people around the edge?\n",
    "\n",
    "What are some benefits and drawbacks of the circular layout versus the force-directed layout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures\n",
    "\n",
    "One benefit of representing data as a network is that the patterns of connections between nodes can reveal useful information.\n",
    "Many standard techniques for investigating the structure of networks have been developed.\n",
    "\n",
    "One of the simplest questions to ask is: which nodes are most important?\n",
    "But what does \"important\" mean exactly?\n",
    "There are several common ways to measure importance, or _centrality_, of nodes in a nework.\n",
    "This section examines several of the most popular.\n",
    "\n",
    "While the _Hamilton_ network in the previous section is simple enough to be illustrative,\n",
    "a historical data set better demonstrates how centrality measures can be applied to real-world networks.\n",
    "This section uses historical data on affilations between organizers of the American Revolution,\n",
    "taken from [Using Metadata to Find Paul Revere](https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_revere_affiliation(\n",
    "        url=\"https://raw.githubusercontent.com/kjhealy/revere/master/data/PaulRevereAppD.csv\"):\n",
    "    data = urllib.request.urlopen(url)\n",
    "    df = pd.read_csv(data).set_index(\"Unnamed: 0\")\n",
    "    people = list(df.index)\n",
    "    groups = list(df.columns)\n",
    "    #\n",
    "    B = nx.Graph()\n",
    "    for column in df.columns:\n",
    "        for row in df[df[column] == 1].index:\n",
    "            B.add_edge(column, row)\n",
    "    return people, groups, B\n",
    "\n",
    "def load_revere(\n",
    "        url=\"https://raw.githubusercontent.com/kjhealy/revere/master/data/PaulRevereAppD.csv\",\n",
    "        threshold=None, dual=False):\n",
    "    # Load the affiliation network\n",
    "    people, groups, B = load_revere_affiliation(url)\n",
    "    # Project the affiliation network onto the set of people\n",
    "    if dual:\n",
    "        G = nxalg.bipartite.projection.weighted_projected_graph(B, groups)\n",
    "    else:\n",
    "        G = nxalg.bipartite.projection.weighted_projected_graph(B, people)\n",
    "    # Threshold\n",
    "    if threshold is not None:\n",
    "        for s, t, data in list(G.edges(data=True)):\n",
    "            if data[\"weight\"] < threshold:\n",
    "                G.remove_edge(s,t)\n",
    "    # Copy \"weight\" data to \"value\" needed by visjs\n",
    "    w = nx.get_edge_attributes(G, \"weight\")\n",
    "    nx.set_edge_attributes(G, w, \"value\")\n",
    "    return G\n",
    "\n",
    "# Standardize a vector to 0 mean and unit variance\n",
    "def scale(v):\n",
    "    return (v - v.mean()) / v.std()\n",
    "\n",
    "# Return a data frame sorted by a node's centrality relative the mean of its centralities\n",
    "def rel_centrality(df, measure, labels=dict()):\n",
    "    name = 'rel_{}'.format(measure)\n",
    "    return pd.DataFrame({\n",
    "        name: scale(df[measure]) / df['mean_centrality'],\n",
    "        \"label\": [labels.get(x, x) for x in df.index]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell begins by loading the data into a `networkx` graph. As is, an analysis of the data will reveal Paul Revere to be highly central by all measures [Healey2013] so to make the example more interesting, let's ask this: if Paul Revere had been on vacation, who might have notified the Massachusetts Provincial Congress of the impending attack in his place? To do so, we remove Paul Revere from the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_revere()\n",
    "people, groups, B = load_revere_affiliation()\n",
    "G.remove_node('Revere.Paul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, the next cell visualizes the network. Take a minute to examine the network and consider the following questions:\n",
    "* Who might act as a bridge between different parts of the network?\n",
    "* Who are the most well-connected?\n",
    "* Who might play a role similar to Paul Revere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_visjs(G, scale=1500, title=\"American Revolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find centrality\n",
    "Now let's move on to examine the centralities. The next cell uses `networkx` to calculate node centralities and then stores them in a data frame. For each node we also calculate a mean centrality value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\": G.nodes(), \"label\": G.nodes()}).set_index(\"id\")\n",
    "df['degree'] = pd.Series(nx.degree_centrality(G))\n",
    "df['betweenness'] = pd.Series(nx.betweenness_centrality(G))\n",
    "df['closeness'] = pd.Series(nx.closeness_centrality(G))\n",
    "df['eigenvector'] = pd.Series(nx.eigenvector_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of all centrality measures\n",
    "df['mean_centrality'] = (\n",
    "    scale(df['degree'])\n",
    "    + scale(df['betweenness'])\n",
    "    + scale(df['closeness'])\n",
    "    + scale(df['eigenvector'])) / 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree\n",
    "\n",
    "One very simple way to find important nodes is to count how many neighbors they have.\n",
    "This measure is called the degree centrality.\n",
    "This number is typically divided by the total number of other nodes in the network, so a value\n",
    "of 0.82 means that a node is connected to 82% of the other nodes.\n",
    "The next cell shows the nodes with the highest degree centralities.\n",
    "\n",
    "Note that some of the people have the same degree. In fact, if two people have exactly the same set of neighbors,\n",
    "all of their centrality scores will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('degree', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of searching for the highest degree centrality nodes, we can find nodes that have an unusually high degree centrality compared to its other centralities.\n",
    "\n",
    "* How do the results below compare to those above?\n",
    "* Why might someone have a high centrality of one type and a low centrality of another type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'degree').sort_values('rel_degree', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness\n",
    "\n",
    "Rather than highly-connected nodes, you might want to find nodes that connect different parts of the network.\n",
    "These types of nodes are sometimes called bridges, or brokers.\n",
    "The betweenness centrality is based on finding the shortest path between nodes.\n",
    "The nodes on that path play the role of bridges, connecting the endpoints.\n",
    "So the betweenness is the fraction of all shortest paths in the network that pass through a given node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('betweenness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'betweenness').sort_values('rel_betweenness', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness\n",
    "\n",
    "A nodes might also be considered important if it is close to many other nodes.\n",
    "In other words, if the paths connecting it to other nodes are all very short.\n",
    "This measure is called closeness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('closeness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'closeness').sort_values('rel_closeness', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvector\n",
    "\n",
    "The last centrality measure covered in this section measures not just how well-connected a node is, but how well-connected its neighbors are as well.\n",
    "This measure is the eigenvector centrality.\n",
    "The PageRank algorithm used by Google to find high quality websites is an extension of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('eigenvector', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_centrality(df, 'eigenvector').sort_values('rel_eigenvector', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret centrality\n",
    "\n",
    "Looking over the above centrality results, consider the questions below. It may be helpful to see the list of organizations a person belonged to, which can be done in the next cell.\n",
    "\n",
    "* Did any of the measures show the same people as being most central?\n",
    "* Members of the Tea Party (e.g. `Collier.Gershom`) have a high degree centrality, but low betweenness centrality. What does that tell you about the Tea Party as compared to other groups?\n",
    "* What would a group with _high_ betweenness and _low_ degree centrality look like?\n",
    "* Of the important people you identified from the visualization, were any in the lists of high-centrality individuals? If so, which types of centrality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.neighbors(B, \"Collier.Gershom\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare centrality measures\n",
    "\n",
    "The following plot shows how different centrality measures are related to each other (in this network).\n",
    "Each graph compares two centrality measures corresponding to its row and column.\n",
    "In each graph, each point represents a single node in the network.\n",
    "\n",
    "Points are drawn with transparency so overlapping points are darker.\n",
    "If a group of people have the same centralities,\n",
    "possibly because they have the same set of neighbors,\n",
    "they appear as a single dark spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store column names in array to keep order consistent\n",
    "measures = [\"degree\", \"betweenness\", \"eigenvector\", \"closeness\"]\n",
    "plt.figure(figsize=(7,6))\n",
    "# Loop through rows and columns\n",
    "# Even though we have 4 measures, we only need 3x3 to compare all\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        # Each row column pair only needs to be plotted once\n",
    "        if row >= col:\n",
    "            # The longest row should correspond to the measure that\n",
    "            # does not appear on a column.\n",
    "            x, y = df[measures[row]], df[measures[(col-1) % 4]]\n",
    "            plt.subplot(3,3,1 + row*3 + col)\n",
    "            plt.plot(x, y, '.', alpha=0.3, markersize=10)\n",
    "            plt.xlim([0, x.max()]); plt.ylim([0, y.max()])\n",
    "        if row == 2:\n",
    "            plt.xlabel(measures[(col - 1) % 4])\n",
    "        if col == 0:\n",
    "            plt.ylabel(measures[row])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community structure\n",
    "\n",
    "What if you didn't know the groups people belonged to and wanted to find them from the network? This is the problem of community detection. There are many ways to find communities. The following cells find and visualize communities using a method that maximizes _modularity_ [CNM2004]. Networks with high modularity have a high number of edges between nodes in the same community and a low number of edges across communities. One benefit of this method is that it determines the best number of communities. In the visualization below, different communities are shown in different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = list(nxcom.greedy_modularity_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_visjs(G, communities=communities, scale=1500, title=\"Community Detection Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting communites\n",
    "When interpreting the communities, it will be helpful to see lists of the organizations each individual belonged to. The next cell will show that list for each individual. To start interpreting the communities, consider the following questions:\n",
    "* Do the communities make sense?\n",
    "* Can you connect particular communities to actual organizations?\n",
    "* Why would two organizations belong to the same community when two others don't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.neighbors(B, \"Church.Benjamin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "\n",
    "It is also informative to consider the shortest paths of a network.\n",
    "For a pair of nodes, the shortest path is the path connecting them in the fewest number of hops.\n",
    "The example below uses a network of characters from the novel _A Storm of Swords_ [BS2016],\n",
    "with edges representing characters mentioned at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_asoiaf():\n",
    "    G = nx.Graph()\n",
    "    with open(\"external/stormofswords.csv\") as f:\n",
    "        f.readline()\n",
    "        for row in f:\n",
    "            source, target, weight = row.split(\",\")\n",
    "            G.add_edge(source, target, weight=int(weight), capacity=1)\n",
    "    return G\n",
    "\n",
    "def path_histogram(G, log=False):\n",
    "    # Find shortest path length for each pair\n",
    "    path_lengths = list(itertools.chain(*[\n",
    "            [length for length in targets.values() if length > 0]\n",
    "        for source, targets in list(nxalg.shortest_path_length(G))]))\n",
    "    # Draw histogram with integer bins\n",
    "    bins = [0.5 + x for x in range(max(path_lengths)+1)]\n",
    "    counts, centers, patches = plt.hist(\n",
    "        path_lengths, bins=bins, rwidth=0.8)\n",
    "    if log:\n",
    "        plt.yscale('log', nonposy='clip')\n",
    "        ymax = np.power(10, np.ceil(np.log10(max(counts))))\n",
    "    else:\n",
    "        place = np.power(10, np.floor(np.log10(max(counts))))\n",
    "        ymax = np.ceil(max(counts) / place) * place\n",
    "    # Plot average shortest path length\n",
    "    mean_path = nxalg.average_shortest_path_length(G)\n",
    "    plt.plot([mean_path, mean_path], [1, ymax], label=\"mean\")\n",
    "    plt.ylim([1, ymax])\n",
    "    plt.xlabel(\"Path length\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "def longest_geodesic(G):\n",
    "    paths = nxalg.shortest_path(G)\n",
    "    longest = 0\n",
    "    longest_path = []\n",
    "    for source, source_paths in paths.items():\n",
    "        for target, path in source_paths.items():\n",
    "            if len(path) > longest:\n",
    "                longest = len(path)\n",
    "                longest_path = path\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load and visualize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = load_asoiaf()\n",
    "visualize_visjs(G, title=\"asoiaf\", scale=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find path lengths\n",
    "Next, plot a histogram of the path lengths as well as the mean path length. The diameter of a network is the length of the longest shortest path.\n",
    "* How do the mean shortest path, mode shortest path, and the longest path compare?\n",
    "* Do you think these values would stay the same if the network was larger? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_histogram(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above found the distribution of paths lengths, but it is also informative to look at individual paths. The following cell prints the shortest path between the two most distant nodes in the network. You might expect the endpoints to be very different in some way, perhaps separated geographically, or socially. Similarly the nodes in the middle are ones that connect distant parts of the network, and are likely to play an important role in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longest_geodesic(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridges and weak ties\n",
    "We can also find edges which act as bridges between different parts of the network. An edge is a bridge if removing it disconnects two parts of a network.\n",
    "More generally, a local bridge connects two nodes that would otherwise be far apart.\n",
    "If removing an edge causes its endpoints to become distance _n_ apart,\n",
    "it is called a local bridge of span n.\n",
    "\n",
    "Bridges are often _weak ties_ [Granovetter1977] because individuals with a strong connection are likely to have common friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def find_bridges(G, labels=None):\n",
    "    bridges = []\n",
    "    for v, w in G.edges():\n",
    "        H = G.copy()\n",
    "        H.remove_edge(v, w)\n",
    "        try:\n",
    "            d = nx.shortest_path_length(H, source=v, target=w)\n",
    "            if d <= 2:\n",
    "                continue\n",
    "        except nx.NetworkXNoPath:\n",
    "            d = float(\"Inf\")\n",
    "        if labels is None:\n",
    "            bridges.append((d, v, w))\n",
    "        else:\n",
    "            bridges.append((d, labels[v], labels[w]))\n",
    "    bridges = sorted(bridges, key=lambda x: x[0], reverse=True)\n",
    "    for b in bridges:\n",
    "        if b[0] == float(\"Inf\"):\n",
    "            print(\"Global bridge:\\t{} <-> {}\".format(b[1], b[2]))\n",
    "        else:\n",
    "            print(\"Local bridge, span {}:\\t{} <-> {}\".format(*b))\n",
    "            \n",
    "def find_global_bridges(G, labels=None):\n",
    "    bridges = nx.algorithms.bridges(G)\n",
    "    for b in bridges:\n",
    "        if labels is None:\n",
    "            v, w = b[0], b[1]\n",
    "        else:\n",
    "            v, w = labels[b[0]], labels[b[1]]\n",
    "        print(\"Global bridge:\\t{} <-> {}\".format(v, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_global_bridges(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find minimum cut\n",
    "Sometimes you might want to know where a network is most fragile.\n",
    "The minimum cut finds the fewest number of links that need to be removed to break a network into two pieces.\n",
    "In the beginning of the _A Song of Ice and Fire_ series, exiled princess Daenerys Targaryen and her brother Viserys seek to reclaim the throne from reigning king Robert Baratheon.\n",
    "You can use the minimum cut to find the links that separate characters connected to the Targaryens from those more closely connected to the Baratheons.\n",
    "\n",
    "First we find the minimum cut: the number of edges separating the two factions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mincut, cuts = nxalg.minimum_cut(G, 'Daenerys', 'Robert')\n",
    "mincut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the min cut. Who in the \"Robert\" cluster is closest to members of the \"Daenerys\" cluster? Why might Daenerys want to identify those people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_visjs(G, communities=cuts, scale=1500, title=\"Mincut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affiliation networks\n",
    "Sometimes it is useful to consider two different types of nodes.\n",
    "Often, this is the case when the two types of nodes are groups and members of those groups,\n",
    "with the edges representing membership.\n",
    "Such networks are called affiliation networks.\n",
    "The American Revolution data from before was created from an affiliation network.\n",
    "The cell below visualizes the full affiliation network.\n",
    "Notice that person nodes are only connected to group nodes and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peopele, groups, B = load_revere_affiliation()\n",
    "visualize_visjs(B, scale=1500, groups=groups, title=\"American Revolution Affiliation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, this affilation network was used to create a network connecting people to people.\n",
    "But we can just as easily create a network connecting groups to groups (if they have a common member) [Breiger1974]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_revere(dual=True)\n",
    "visualize_visjs(G, title=\"American Revolution Groups\", groups=G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted edges\n",
    "In the above example, two groups have an edge between them if they have a common member.\n",
    "But some groups might have only one member in common, while others have many.\n",
    "These differences can be represented by adding a _weight_ do the edge.\n",
    "In this case, weights represent how many members two groups have in common,\n",
    "but weights can represent anything: distance, similarity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_visjs(G, title=\"American Revolution Weighted\", groups=G.nodes(), weight=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your social network\n",
    "Now you can do these analyses on your own social network! Specifically, you can download a list of all of your friends and whether they are friends with each other.\n",
    "This network is called your \"ego network.\"\n",
    "\n",
    "If you use Facebook, you can use the LostCircles plugin for Chrome to download your social network.\n",
    "1. Open the following link in Chrome to install LostCircles:\n",
    "https://chrome.google.com/webstore/detail/lost-circles-facebook-gra/ehpmfdlcppenimpibdifodjgfafkjhjl?hl=en\n",
    "2. Click the LostCircles icon on the Chrome toolbar and select \"Start Loading.\"\n",
    "3. Wait until the menu shows \"100%\" next to \"Start Loading.\"\n",
    "4. Click the LostCircles icon and then \"Download...\" followed by \"JSON (no pics)\". Save the result as `external/LostCircles/egonet.json`.\n",
    "5. Continue to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_lost_circles_json(in_file, name=False):\n",
    "    with open(in_file) as f:\n",
    "        raw = json.load(f)\n",
    "    id_to_name = dict((i, datum[\"name\"]) for i, datum in enumerate(raw['nodes']))\n",
    "    if name:\n",
    "        edges = [(id_to_name[datum[\"source\"]], id_to_name[datum[\"target\"]], {\"capacity\":1}) for datum in raw['links']]\n",
    "    else:\n",
    "        edges = [(datum[\"source\"], datum[\"target\"], {\"capacity\":1}) for datum in raw['links']]\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    return G, id_to_name, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your social network\n",
    "Let's start by visualizing your ego network.\n",
    "* Does it look like there are distinct groups? If so, can you explain why those groups exist?\n",
    "* Is everyone connected? Or are there disconnected components of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, id_to_name, edges = load_lost_circles_json(\"external/LostCircles/egonet.json\")\n",
    "visualize_visjs(G, title=\"Ego Net\", scale=6000, labels=id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social network communities\n",
    "Try finding communities within your social network. Do the communities correspond to the groups you identified above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nxalg.community.greedy_modularity_communities(G)\n",
    "visualize_visjs(G, communities=communities, title=\"Ego Net Communities\", scale=6000, labels=id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social network centrality\n",
    "Now you can repeat the centrality analysis for members of your own ego network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality measures\n",
    "df = pd.DataFrame({\"id\": G.nodes(), \"label\": [id_to_name[x] for x in G.nodes()]}).set_index(\"id\")\n",
    "df['degree'] = pd.Series(nx.degree_centrality(G))\n",
    "df['betweenness'] = pd.Series(nx.betweenness_centrality(G))\n",
    "df['closeness'] = pd.Series(nx.closeness_centrality(G))\n",
    "df['eigenvector'] = pd.Series(nx.eigenvector_centrality(G))\n",
    "# Calculate mean of all centrality measures\n",
    "df['mean_centrality'] = (\n",
    "    scale(df['degree'])\n",
    "    + scale(df['betweenness'])\n",
    "    + scale(df['closeness'])\n",
    "    + scale(df['eigenvector'])) / 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree\n",
    "These are the most highly connected members of your network. Do they have anything in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('degree', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'degree', labels=id_to_name).sort_values('rel_degree', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness\n",
    "These are the individuals who connect different parts of your network. Can you think of reasons these particular individuals might play that role?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('betweenness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'betweenness', labels=id_to_name).sort_values('rel_betweenness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness\n",
    "These individuals are, on average, closest to everyone you know. Do the results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('closeness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'closeness', labels=id_to_name).sort_values('rel_closeness', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvector\n",
    "These individuals are most connected to highly connected individuals. How do they compare to those identified by other methods? Can you explain why these individuals would have high centrality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('eigenvector', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_centrality(df, 'eigenvector', labels=id_to_name).sort_values('rel_eigenvector', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find giant component\n",
    "Before moving on to examine path length, it is important to consider whether the network is connected. Were there any groups of nodes with no edges going to the rest of the network? If so, some pairs of nodes aren't connected by a path. To get around this, we can examine only the largest connected component, called the _giant component_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def giant_component(G):\n",
    "    giant_component = sorted(nxalg.connected_components(G), reverse=True, key=len)[0]\n",
    "    for v in set(G.nodes()) - giant_component:\n",
    "        G.remove_node(v)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = giant_component(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social network path lengths\n",
    "Now let's look at the histogram of paths in your social network. How does it compare to the _A Song of Ice and Fire_ network above? Are most paths longer, shorter, or the same? Are any paths much longer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_histogram(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the path between the most distant nodes. Why might the nodes on the ends be so far separated? Why are the nodes in the middle good at connecting them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([id_to_name[i] for i in longest_geodesic(G)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find bridges\n",
    "Next, consider the bridges in your social network. Do they correspond to weak ties as hypothesized in [Granovetter1977]? Weak ties can be useful for searching a social network because they connect different communities. For example, if you were looking for a job, who would you ask? Do they appear in any bridges?\n",
    "\n",
    "The cell below will find only global bridges by default. If no global bridges exist, you can change the first line to `local = True` to find local bridges as well. Finding local bridges may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local = False\n",
    "if local:\n",
    "    find_bridges(G, labels=id_to_name)\n",
    "else:\n",
    "    find_global_bridges(G, labels=id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Healey2013] Healy, K. 2013. \"Using Metadata to Find Paul Revere.\" https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/\n",
    "\n",
    "[CNM2004] Clauset, A., Newman, M. E., & Moore, C. (2004). Finding community structure in very large networks. Physical review E, 70(6).\n",
    "\n",
    "[RLWGBF2017] Rosenthal, S. B., Len, J., Webster, M., Gary, A., Birmingham, A., & Fisch, K. M. (2017). Interactive network visualization in Jupyter notebooks: visJS2jupyter. Bioinformatics.\n",
    "\n",
    "[BS2016] A. Beveridge and J. Shan, \"Network of Thrones,\" Math Horizons Magazine , Vol. 23, No. 4 (2016), pp. 18-22\n",
    "\n",
    "[Breiger1974] Breiger, R. L. (1974). The duality of persons and groups. Social forces, 53(2), 181-190.\n",
    "\n",
    "[Granovetter1977] Granovetter, M. S. (1977). The strength of weak ties. In Social networks (pp. 347-367)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
