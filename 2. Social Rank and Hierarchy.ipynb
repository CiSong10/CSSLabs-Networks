{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS Lab: Social Rank and Hierarchy\n",
    "Network analysis can be used to examine social status within a community. This lab will use data from the 1995-1997 Teenage Friends and Lifestyle study [MA1997]. This study collected friendship and other data from a group of 50 teenage girls over the course of three years.\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Directed networks\n",
    "    1. Load and visualize the social network\n",
    "3. Social status\n",
    "    1. Minimum violation rankings\n",
    "    2. Eigenvector centrality\n",
    "    3. Spring rank\n",
    "    4. Compare MVR approximations\n",
    "    5. Analyze friendships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import urllib.request\n",
    "import networkx as nx\n",
    "import networkx.algorithms as nxalg\n",
    "import networkx.algorithms.community as nxcom\n",
    "import networkx.readwrite as nxrw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as spstats\n",
    "import visJS2jupyter.visJS_module as vjs\n",
    "import re\n",
    "from springrank.SpringRank_tools import SpringRank\n",
    "from springrank.tools import build_graph_from_adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_social():\n",
    "    G = nx.DiGraph()\n",
    "    edges = dict()\n",
    "    with open(\"external/facebook-wosn-wall/out.facebook-wosn-wall\") as f:\n",
    "        for row in f:\n",
    "            if row[0] == \"%\":\n",
    "                continue\n",
    "            try:\n",
    "                data = [int(x) for x in re.split(\"\\s+\", row.strip())]\n",
    "                source, target, weight, timestamp = data\n",
    "            except ValueError:\n",
    "                print(row)\n",
    "                print(re.split(\"\\s+\", row))\n",
    "                raise\n",
    "            try:\n",
    "                edges[(source, target)] += 1\n",
    "            except KeyError:\n",
    "                edges[(source, target)] = 1\n",
    "    for source, target in edges:\n",
    "        G.add_edge(source, target)\n",
    "    return G\n",
    "\n",
    "def load_tfls():\n",
    "    G = nx.DiGraph()\n",
    "    with open(\"external/s50_data/s50-network1.dat\") as f:\n",
    "        for row, row_data in enumerate(f):\n",
    "            for col, cell_data in enumerate(re.split(\"\\s\", row_data.strip())):\n",
    "                cell_data = float(cell_data)\n",
    "                if cell_data != 0:\n",
    "                    G.add_edge(row, col, weight=cell_data, value=cell_data)\n",
    "    nx.set_node_attributes(G, dict((v, v) for v in G.nodes()), name=\"label\")\n",
    "    return G\n",
    "\n",
    "\n",
    "def get_colors():\n",
    "    phi = (1 + math.sqrt(5)) / 2\n",
    "    color = []\n",
    "    for i in range(1, 20):\n",
    "        theta = phi * i * math.pi * 2\n",
    "        x = 128 + math.floor(64*math.sin(theta))\n",
    "        y = 128 + math.floor(64*math.cos(theta))\n",
    "        color.append((x, x, y))\n",
    "    return color\n",
    "\n",
    "\n",
    "def visualize_visjs(\n",
    "        G, communities=None, colors=None, default_color=\"192,192,192\",\n",
    "        node_size_field=\"node_size\", layout=\"spring\", scale=500, pos=None,\n",
    "        groups=None, weight=None, labels=dict(), title=\"\", node_alpha=1.0):\n",
    "    # Get list of nodes and edges\n",
    "    nodes = list(G.nodes())\n",
    "    edges = list(G.edges())\n",
    "    # Change node shapes for bipartite graph\n",
    "    if groups is None:\n",
    "        node_shapes = dict()\n",
    "        node_sizes = dict()\n",
    "        node_colors = dict()\n",
    "    else:\n",
    "        node_shapes = dict((n, \"square\") for n in groups)\n",
    "        node_sizes = dict((n, 15) for n in groups)\n",
    "        node_colors = dict((n, \"192,128,0\") for n in groups)\n",
    "    # Per-node properties\n",
    "    nodes_dict = dict((n, {\n",
    "        \"id\": str(labels.get(n, n)),\n",
    "        \"node_size\": node_sizes.get(n, 5),\n",
    "        \"node_shape\": node_shapes.get(n, \"dot\")\n",
    "        }) for n in nodes)\n",
    "    # Generate a layout for the nodes\n",
    "    edge_smooth_enabled = False\n",
    "    edge_width = 4\n",
    "    edge_arrow_scale = 2\n",
    "    if communities is not None and pos is None:\n",
    "        # Generate initial positions based on community\n",
    "        phi = 3.14 / len(nodes)\n",
    "        community_node = []\n",
    "        # Create list of nodes and their communities\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                community_node.append((i, node))\n",
    "        # Sort by community and\n",
    "        community_node = sorted(community_node)\n",
    "        # Generate initial position by placing communities around a circle\n",
    "        pos = dict((d[1], (math.cos(i*phi), math.sin(i*phi))) for i, d in enumerate(community_node))\n",
    "    if layout == \"circle\":\n",
    "        pos = nx.circular_layout(G, scale=scale)\n",
    "    elif layout == \"spring\":\n",
    "        pos = nx.spring_layout(G, k=3/math.sqrt(len(nodes)), scale=scale, pos=pos)\n",
    "    else:\n",
    "        edge_smooth_enabled = True\n",
    "    # Assign position\n",
    "    for n in nodes:\n",
    "        nodes_dict[n][\"x\"] = pos[n][0]\n",
    "        nodes_dict[n][\"y\"] = pos[n][1]\n",
    "    # Calculate bounds for scaling\n",
    "    x_min = min(pos.values(), key=lambda x: x[0])[0]\n",
    "    x_max = max(pos.values(), key=lambda x: x[0])[0]\n",
    "    y_min = min(pos.values(), key=lambda x: x[1])[1]\n",
    "    y_max = max(pos.values(), key=lambda x: x[1])[1]\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    max_range = max(x_range, y_range)\n",
    "    # If we have communities, assign color based on community\n",
    "    if colors is None:\n",
    "        colors = [\"{},{},{}\".format(*c) for c in get_colors()]\n",
    "    if communities is not None:\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                try:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},{})\".format(colors[i], node_alpha)\n",
    "                    nodes_dict[node][\"color_index\"] = i\n",
    "                except IndexError:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},{})\".format(default_color, node_alpha)\n",
    "    # Update color for bipartite nodes\n",
    "    for node, node_attr in nodes_dict.items():\n",
    "        if node in node_colors:\n",
    "            node_attr[\"color\"] = \"rgba({},{})\".format(node_colors[node], node_alpha)\n",
    "    # Map node labels to contiguous ids\n",
    "    node_map = dict(zip(nodes,range(len(nodes))))\n",
    "    # Determine edge colors\n",
    "    edge_colors_idx = {}\n",
    "    for source, target in edges:\n",
    "        source_color = nodes_dict[source].get(\"color_index\", None)\n",
    "        target_color = nodes_dict[target].get(\"color_index\", None)\n",
    "        if source_color == target_color and source_color is not None:\n",
    "            edge_colors_idx[(source, target)] = source_color\n",
    "    edge_colors = dict(\n",
    "        (e,colors[c])\n",
    "        for e, c in edge_colors_idx.items() if c < len(colors))\n",
    "    # Per-edge properties, use contiguous ids to identify nodes\n",
    "    edge_scale = math.ceil(max_range / 200)\n",
    "    edges_dict = []\n",
    "    for source, target, data in G.edges(data=True):\n",
    "        edge = {\n",
    "            \"source\": node_map[source],\n",
    "            \"target\": node_map[target],\n",
    "            \"title\":'test',\n",
    "            \"color\": \"rgba({},0.3)\".format(edge_colors.get((source,target), default_color)),\n",
    "            \"edge_width_field\": \"value\",\n",
    "            \"value\": data.get(\"value\", 1) * edge_scale\n",
    "        }\n",
    "        edges_dict.append(edge)\n",
    "    # Convert nodes dict to node list\n",
    "    nodes_list = [nodes_dict[n] for n in nodes]\n",
    "    # Check for directed graph\n",
    "    if G.__class__ == nx.classes.digraph.DiGraph:\n",
    "        directed = True\n",
    "    else:\n",
    "        directed = False\n",
    "    # Call visjs\n",
    "    return vjs.visjs_network(\n",
    "        nodes_list, edges_dict,\n",
    "        node_size_field=\"node_size\",\n",
    "        node_size_multiplier=10.0,\n",
    "        edge_width_field=\"value\",\n",
    "        edge_width=edge_width,\n",
    "        edge_arrow_to=directed,\n",
    "        edge_arrow_to_scale_factor=edge_arrow_scale,\n",
    "        edge_smooth_enabled=edge_smooth_enabled,\n",
    "        edge_smooth_type=\"curvedCW\",\n",
    "        graph_id=hash(title))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social status\n",
    "When members of a social group can be ordered in terms of social status, it forms a pecking order. Directed network data can be used to uncover an underlying pecking order if it exists. An unreciprocated friendship can be a sign of a difference in social standing. The person who doesn't list the friendship may do so because they have too many friends to list, or because they don't want to list someone unpopular.\n",
    "\n",
    "### Minimum violation rankings\n",
    "In a perfect pecking order, friendships would only go from lower-ranked nodes to higher-ranked nodes.\n",
    "So to find a pecking order, we look for a _minimum-violation ranking_: an ordering with as few links going from high-status to low-status individuals as possible.\n",
    "Such an ordering may or may not exist.\n",
    "The more violoations in the MVR, the less heirarchical a group is.\n",
    "The example below allows you to test different orderings for the number of violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "def scale(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def giant_component(G):\n",
    "    giant_component = sorted(nxalg.weakly_connected_components(G), reverse=True, key=len)[0]\n",
    "    for v in set(G.nodes()) - giant_component:\n",
    "        G.remove_node(v)\n",
    "    return G\n",
    "\n",
    "def get_spring_rank(G):\n",
    "    nodes = list(G.nodes())\n",
    "    A=nx.to_numpy_matrix(G,nodelist=list(nodes))\n",
    "    rank = dict(zip(nodes, scale(SpringRank(A,alpha=0.0,l0=1.0,l1=1.0))))\n",
    "    order = dict((elt[0], i) for i, elt in enumerate(sorted(rank.items(), key=lambda x: x[1], reverse=True)))\n",
    "    return rank, order\n",
    "\n",
    "def get_eigenvector_rank(G):\n",
    "    all_nodes = set(G.nodes())\n",
    "    components = nx.algorithms.components.weakly_connected_components(G)\n",
    "    rank = dict()\n",
    "    for c in components:\n",
    "        H = G.copy()\n",
    "        H.remove_nodes_from(all_nodes - set(c))\n",
    "        component_rank = nx.algorithms.centrality.eigenvector_centrality_numpy(H)\n",
    "        rank.update(component_rank)\n",
    "    nodes, ranks = zip(*list(rank.items()))\n",
    "    ranks = -1 * scale(ranks)\n",
    "    rank = dict(zip(list(nodes), list(ranks)))\n",
    "    order = dict((elt[0], i) for i, elt in enumerate(sorted(rank.items(), key=lambda x: x[1], reverse=True)))\n",
    "    return rank, order\n",
    "\n",
    "def count_violations(G, order):\n",
    "    rank_differences = []\n",
    "    violations = 0\n",
    "    for v, w in G.edges():\n",
    "        difference = order[w] - order[v]\n",
    "        rank_differences.append(difference)\n",
    "        if difference < 0:\n",
    "            violations += 1\n",
    "    return rank_differences, violations\n",
    "    \n",
    "def plot_ordering(G, rank, title=\"Ordering\", scale=150):\n",
    "    nodes = list(G.nodes())\n",
    "    pos = dict((v, (0, r*scale)) for v, r in rank.items())\n",
    "    return visualize_visjs(G, layout=None, pos=pos, scale=scale, title=title, node_alpha=0.5)\n",
    "\n",
    "def mvr_example():\n",
    "    H = nx.DiGraph()\n",
    "    H.add_edges_from([\n",
    "        ('Lemon', 'Cotton'),\n",
    "        ('Mia', 'Cotton'),\n",
    "        ('Mia', 'Lemon'),\n",
    "        ('Mia', 'Bagel'),\n",
    "        ('Bagel', 'Lemon'),\n",
    "        ('Setzer', 'Cotton'),\n",
    "        ('Lemon', 'Setzer')\n",
    "    ])\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, visualize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = mvr_example()\n",
    "visualize_visjs(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define an ordering, visualize it, and count the number of violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To re-order the nodes, change these numbers\n",
    "mvr_order = {\n",
    "    \"Bagel\":  0,\n",
    "    \"Cotton\": 1,\n",
    "    \"Lemon\":  2,\n",
    "    \"Mia\":    3,\n",
    "    \"Setzer\": 4\n",
    "}\n",
    "# Count the violations and visualize\n",
    "rank_differences, violations = count_violations(H, mvr_order)\n",
    "print(\"Violations:\", violations)\n",
    "plot_ordering(H, mvr_order, title=\"MVR Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which edges count as violations? There is an ordering for this network with 0 violations, can you find it? Try re-running the above cell after changing the rank numbers for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teenage Friendship and Lifestyle Study\n",
    "### Load and visualize the social network\n",
    "Now we'll load and visualize friendship data from a real social network. The [MA1997] study determined friendships by asking participants to name their top friends. This method has in interesting feature: it is possible for a participant to list someone as a friend who does not list the participant as a friend. The friendship ties are _directed_. In the visualization, arrows go from the participant to the individuals they named as friends. Reciprocated friendships have arrows on both ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_tfls()\n",
    "visualize_visjs(G, scale=1000, title=\"Full Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MVRs\n",
    "\n",
    "We'd like to find the MVR. Unfortunately, finding the MVR is very difficult even with a lot of computing power (in computer science terms, it's NP-hard).\n",
    "However, several approximation methods exist. Some common approximations are explored below.\n",
    "\n",
    "\n",
    "TODO different approx different order / violations.\n",
    "\n",
    "### Eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = giant_component(G)\n",
    "# Calculate the rank\n",
    "er_rank, er_order = get_eigenvector_rank(G)\n",
    "# Plot the ordering\n",
    "plot_ordering(G, er_rank, title=\"Eigenvector Rank\", scale=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_differences, violations = count_violations(G, er_order)\n",
    "print(\"Violations:\", violations)\n",
    "print(\"Violation percent:\", violations / len(list(G.edges())))\n",
    "print(\"Mean rank difference:\", np.mean(rank_differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpringRank\n",
    "The example below uses SpringRank [BLN2013] to find an approximate MVR by modeling individuals as particles connected by springs that pull towards popular individuals and push away from unpopular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest connected component\n",
    "G = giant_component(G)\n",
    "# Calculate the rank\n",
    "sr_rank, sr_order = get_spring_rank(G)\n",
    "# Plot the ordering\n",
    "plot_ordering(G, sr_rank, title=\"Spring Rank\", scale=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_differences, violations = count_violations(G, sr_order)\n",
    "print(\"Violations:\", violations)\n",
    "print(\"Violation percent:\", violations / len(list(G.edges())))\n",
    "print(\"Mean rank difference:\", np.mean(rank_differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare approximations\n",
    "\n",
    "TODO violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = er_order.keys()\n",
    "plt.figure(figsize=(8,4))\n",
    "subplot(1,2,1)\n",
    "plt.plot([er_order[v] for v in nodes], [sr_order[v] for v in nodes], '.')\n",
    "title(\"Rank order\"); xlabel(\"Eigenvector\"); ylabel(\"SpringRank\")\n",
    "subplot(1,2,2)\n",
    "plt.plot([er_rank[v] for v in nodes], [sr_rank[v] for v in nodes], '.')\n",
    "title(\"Centrality score\"); xlabel(\"Eigenvector\"); ylabel(\"SpringRank\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(min(rank_differences) - 0.5, max(rank_differences) + 0.5)\n",
    "plt.hist(rank_differences, bins=bins)\n",
    "xlabel(\"Rank difference\"); ylabel(\"Count\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_tfls_behavior():\n",
    "    result = dict()\n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    t3 = []\n",
    "    with open(\"external/s50_data/s50-alcohol.dat\") as f:\n",
    "        for row in f:\n",
    "            a, b, c = re.split('\\s+', row.strip())\n",
    "            t1.append(float(a))\n",
    "            t2.append(float(b))\n",
    "            t3.append(float(c))\n",
    "    result[\"alcohol\"] = [t1, t2, t3]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = load_tfls_behavior()\n",
    "nodes = sr_rank.keys()\n",
    "x = [sr_rank[n] for n in nodes]\n",
    "y = [behavior[\"alcohol\"][1][n] for n in nodes]\n",
    "plt.plot(x, y, '.')\n",
    "r, p = spstats.pearsonr(x, y)\n",
    "plt.title(\"r={:.2}, p={:.3}\".format(r, p))\n",
    "plt.xlabel(\"Spring Rank\"); plt.ylabel(\"Alcohol Use\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[BLN2013] De Bacco, C., Larremore, D. B., & Moore, C. (2017). A physical model for efficient ranking in networks. arXiv preprint arXiv:1709.09002.\n",
    "\n",
    "[MA1997] L. Michell, and A. Amos, \"Girls, pecking order and smoking.\" Social Science & Medicine 44(12), 1861-1869 (1997)\n",
    "\n",
    "[KONECT2017] Facebook wall posts network dataset -- KONECT, April 2017.\n",
    "\n",
    "[VMCG2009] Bimal Viswanath, Alan Mislove, Meeyoung Cha, and Krishna P. Gummadi. On the evolution of user interaction in Facebook. In Proc. Workshop on Online Social Networks, pages 37--42, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
