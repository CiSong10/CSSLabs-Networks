{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS Lab: Social Rank and Hierarchy\n",
    "Network analysis can be used to examine social status within a community. This lab will use data from the 1995-1997 Teenage Friends and Lifestyle study [MA1997]. This study collected friendship and other data from a group of teenage students over the course of three years.\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Directed networks\n",
    "    1. Load and visualize the social network\n",
    "3. Social status\n",
    "    1. Minimum violation rankings\n",
    "    2. Eigenvector centrality\n",
    "    3. Spring rank\n",
    "    4. Compare MVR approximations\n",
    "    5. Analyze friendships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import networkx as nx\n",
    "import networkx.algorithms as nxalg\n",
    "import networkx.algorithms.community as nxcom\n",
    "import networkx.readwrite as nxrw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as spstats\n",
    "import visJS2jupyter.visJS_module as vjs\n",
    "import re\n",
    "from springrank.SpringRank_tools import SpringRank\n",
    "from springrank.tools import build_graph_from_adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_tfls(wave=1):\n",
    "    G = nx.DiGraph()\n",
    "    with open(\"external/TFLS/friendship-{}.csv\".format(wave)) as f:\n",
    "        # Read header\n",
    "        labels = re.split(\",\", f.readline().strip())[1:]\n",
    "        labels = [x.strip('\"') for x in labels]\n",
    "        # Read data\n",
    "        for row, row_data in enumerate(f):\n",
    "            cells = re.split(\",\", row_data.strip())\n",
    "            row_label = cells[0].strip('\"')\n",
    "            cells = cells[1:]\n",
    "            for col, cell_data in enumerate(cells):\n",
    "                if row_label == labels[col]:\n",
    "                    continue\n",
    "                if cell_data == \"1\" or cell_data == \"2\":\n",
    "                    cell_data = 1\n",
    "                    G.add_edge(row_label, labels[col], weight=cell_data, value=cell_data)\n",
    "    nx.set_node_attributes(G, dict((v, v) for v in G.nodes()), name=\"label\")\n",
    "    return G\n",
    "\n",
    "def get_colors():\n",
    "    phi = (1 + math.sqrt(5)) / 2\n",
    "    color = []\n",
    "    for i in range(1, 20):\n",
    "        theta = phi * i * math.pi * 2\n",
    "        x = 128 + math.floor(64*math.sin(theta))\n",
    "        y = 128 + math.floor(64*math.cos(theta))\n",
    "        color.append((x, x, y))\n",
    "    return color\n",
    "\n",
    "def visualize_visjs(\n",
    "        G, communities=None, colors=None, default_color=\"192,192,192\",\n",
    "        node_size_field=\"node_size\", layout=\"spring\", scale=500, pos=None,\n",
    "        groups=None, smooth=False, weight=None, labels=dict(), title=\"\",\n",
    "        shadow=True, shape=\"dot\", node_colors=dict(), node_alpha=1.0,\n",
    "        edge_colors=dict()):\n",
    "    # Get list of nodes and edges\n",
    "    nodes = list(G.nodes())\n",
    "    edges = list(G.edges())\n",
    "    # Change node shapes for bipartite graph\n",
    "    if groups is None:\n",
    "        node_shapes = dict()\n",
    "        node_sizes = dict()\n",
    "    else:\n",
    "        node_shapes = dict((n, \"square\") for n in groups)\n",
    "        node_sizes = dict((n, 15) for n in groups)\n",
    "        node_colors = dict((n, \"192,128,0\") for n in groups)\n",
    "    # Per-node properties\n",
    "    nodes_dict = dict((n, {\n",
    "        \"id\": str(labels.get(n, n)),\n",
    "        \"node_size\": node_sizes.get(n, 5),\n",
    "        \"node_shape\": node_shapes.get(n, shape),\n",
    "        \"border_width\": 2,\n",
    "        \"color\": \"rgba({},{})\".format(node_colors.get(n, default_color), node_alpha)\n",
    "        }) for n in nodes)\n",
    "    if shape == \"cat\":\n",
    "        for key, node in nodes_dict.items():\n",
    "            node[\"node_shape\"] = \"image\"\n",
    "            node[\"node_image\"] = \"cat.png\"\n",
    "    # Generate a layout for the nodes\n",
    "    edge_smooth_enabled = smooth\n",
    "    edge_width = 4\n",
    "    edge_arrow_scale = 2\n",
    "    if communities is not None and pos is None:\n",
    "        # Generate initial positions based on community\n",
    "        phi = 3.14 / len(nodes)\n",
    "        community_node = []\n",
    "        # Create list of nodes and their communities\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                community_node.append((i, node))\n",
    "        # Sort by community and\n",
    "        community_node = sorted(community_node)\n",
    "        # Generate initial position by placing communities around a circle\n",
    "        pos = dict((d[1], (math.cos(i*phi), math.sin(i*phi))) for i, d in enumerate(community_node))\n",
    "    if layout == \"circle\":\n",
    "        pos = nx.circular_layout(G, scale=scale)\n",
    "    elif layout == \"spring\":\n",
    "        pos = nx.spring_layout(G, k=3/math.sqrt(len(nodes)), scale=scale, pos=pos)\n",
    "    # Assign position\n",
    "    for n in nodes:\n",
    "        nodes_dict[n][\"x\"] = pos[n][0]\n",
    "        nodes_dict[n][\"y\"] = pos[n][1]\n",
    "    # Calculate bounds for scaling\n",
    "    x_min = min(pos.values(), key=lambda x: x[0])[0]\n",
    "    x_max = max(pos.values(), key=lambda x: x[0])[0]\n",
    "    y_min = min(pos.values(), key=lambda x: x[1])[1]\n",
    "    y_max = max(pos.values(), key=lambda x: x[1])[1]\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    max_range = max(x_range, y_range)\n",
    "    # If we have communities, assign color based on community\n",
    "    if colors is None:\n",
    "        colors = [\"{},{},{}\".format(*c) for c in get_colors()]\n",
    "    if communities is not None:\n",
    "        for i, com in enumerate(sorted(communities, key=lambda x: len(x), reverse=True)):\n",
    "            for node in com:\n",
    "                try:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},{})\".format(colors[i], node_alpha)\n",
    "                    nodes_dict[node][\"color_index\"] = i\n",
    "                except IndexError:\n",
    "                    nodes_dict[node][\"color\"] = \"rgba({},{})\".format(default_color, node_alpha)\n",
    "    # Update color for bipartite nodes\n",
    "    for node, node_attr in nodes_dict.items():\n",
    "        if node in node_colors:\n",
    "            node_attr[\"color\"] = \"rgba({},{})\".format(node_colors.get(node, default_color), node_alpha)\n",
    "    # Map node labels to contiguous ids\n",
    "    node_map = dict(zip(nodes,range(len(nodes))))\n",
    "    # Determine edge colors\n",
    "    edge_colors_idx = {}\n",
    "    for source, target in edges:\n",
    "        source_color = nodes_dict[source].get(\"color_index\", None)\n",
    "        target_color = nodes_dict[target].get(\"color_index\", None)\n",
    "        if source_color == target_color and source_color is not None:\n",
    "            edge_colors_idx[(source, target)] = source_color\n",
    "    for e, c in edge_colors_idx.items():\n",
    "        if c < len(colors) and e not in edge_colors:\n",
    "            edge_colors[e] = colors[c]\n",
    "    # Per-edge properties, use contiguous ids to identify nodes\n",
    "    edge_scale = math.ceil(max_range / 200)\n",
    "    edges_dict = []\n",
    "    for source, target, data in G.edges(data=True):\n",
    "        edge = {\n",
    "            \"source\": node_map[source],\n",
    "            \"target\": node_map[target],\n",
    "            \"title\":'test',\n",
    "            \"color\": \"rgba({},0.3)\".format(edge_colors.get((source,target), default_color)),\n",
    "            \"edge_width_field\": \"value\",\n",
    "            \"value\": data.get(\"value\", 1) * edge_scale\n",
    "        }\n",
    "        edges_dict.append(edge)\n",
    "    # Convert nodes dict to node list\n",
    "    nodes_list = [nodes_dict[n] for n in nodes]\n",
    "    # Check for directed graph\n",
    "    if G.__class__ == nx.classes.digraph.DiGraph:\n",
    "        directed = True\n",
    "    else:\n",
    "        directed = False\n",
    "    # Call visjs\n",
    "    return vjs.visjs_network(\n",
    "        nodes_list, edges_dict,\n",
    "        node_size_field=\"node_size\",\n",
    "        node_size_multiplier=10.0,\n",
    "        node_shadow_enabled=shadow,\n",
    "        node_color_border=\"rgba(0,0,0,{})\".format(node_alpha),\n",
    "        edge_width_field=\"value\",\n",
    "        edge_width=edge_width,\n",
    "        edge_arrow_to=directed,\n",
    "        edge_arrow_to_scale_factor=edge_arrow_scale,\n",
    "        edge_smooth_enabled=edge_smooth_enabled,\n",
    "        edge_smooth_type=\"curvedCW\",\n",
    "        graph_id=hash(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_visjs(nx.karate_club_graph(), title=\"karate\", node_colors={0: \"255,255,0\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social status\n",
    "When members of a social group can be ordered in terms of social status, it forms a pecking order. Directed network data can be used to uncover an underlying pecking order if it exists. An unreciprocated friendship can be a sign of a difference in social standing. The person who doesn't list the friendship may do so because they have too many friends to list, or because they don't want to list someone unpopular.\n",
    "\n",
    "### Minimum violation rankings\n",
    "In a perfect pecking order, friendships would only go from lower-ranked nodes to higher-ranked nodes.\n",
    "So to find a pecking order, we look for a _minimum-violation ranking_: an ordering with as few links going from high-status to low-status individuals as possible.\n",
    "Such an ordering may or may not exist.\n",
    "The more violoations in the MVR, the less heirarchical a group is.\n",
    "The example below allows you to test different orderings for the number of violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "def scale(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def unit(rank):\n",
    "    v = rank.values()\n",
    "    span = max(v) - min(v)\n",
    "    return dict((k, (x - min(v)) / span) for k, x in rank.items())\n",
    "\n",
    "def giant_component(G):\n",
    "    giant_component = sorted(nxalg.weakly_connected_components(G), reverse=True, key=len)[0]\n",
    "    for v in set(G.nodes()) - giant_component:\n",
    "        G.remove_node(v)\n",
    "    return G\n",
    "\n",
    "def get_mvr_rank(G, time_limit=60):\n",
    "    # Iterative implementation to test all configurations\n",
    "    labels = list(G.nodes())\n",
    "    N = len(labels)\n",
    "    ranking = []\n",
    "    # Lists of remaining labels once i places have been assigned\n",
    "    remaining = [[] for i in range(N)]\n",
    "    remaining[0] = list(labels)\n",
    "    # Upper limit is all pairs\n",
    "    best_violations = N * (N - 1) / 2\n",
    "    best_ranking = []\n",
    "    start = time.time()\n",
    "    last = start\n",
    "    i = 0\n",
    "    tried = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        # Check for time limit, and sleep periodically to avoid locking cpu\n",
    "        if i % 1000 == 0:\n",
    "            t = time.time()\n",
    "            delta = t - start\n",
    "            if delta >= time_limit:\n",
    "                print(\"Time limit exceeded\")\n",
    "                print(\"{} of {:0.2e} configurations in {:0.2f}s\".format(i, math.factorial(N), delta))\n",
    "                raise RuntimeError\n",
    "            time.sleep(0)\n",
    "        try:\n",
    "            # Assign the next remaining label to the current place and move to the next\n",
    "            ranking.append(remaining[len(ranking)].pop())\n",
    "            if len(ranking) == N:\n",
    "                # Out of places, compare the full assignment to the best so far\n",
    "                trial_ranking = dict((label, i) for i, label in enumerate(ranking))\n",
    "                rank_differences, violations = count_violations(G, trial_ranking)\n",
    "                if violations < best_violations:\n",
    "                    best_violations = violations\n",
    "                    best_ranking = trial_ranking\n",
    "                tried += 1\n",
    "                # Backtrack\n",
    "                ranking.pop()\n",
    "            else:\n",
    "                # Move to next place\n",
    "                remaining[len(ranking)] = list(set(labels) - set(ranking))\n",
    "        except IndexError:\n",
    "            # No labels remaining, backtrack\n",
    "            try:\n",
    "                ranking.pop()\n",
    "            except IndexError:\n",
    "                # Unable to backtrack, all labels have been tried for all places\n",
    "                break\n",
    "    best_order = dict((x, N - i) for x, i in best_ranking.items())\n",
    "    return best_ranking, best_order\n",
    "\n",
    "def get_spring_rank(G):\n",
    "    nodes = list(G.nodes())\n",
    "    A=nx.to_numpy_matrix(G,nodelist=list(nodes))\n",
    "    # Reverse spring rank so positive numbers represent higher status\n",
    "    rank = dict(zip(nodes, -1 * SpringRank(A,alpha=0.0,l0=1.0,l1=1.0)))\n",
    "    order = dict((elt[0], i) for i, elt in enumerate(sorted(rank.items(), key=lambda x: x[1])))\n",
    "    return rank, order\n",
    "\n",
    "def get_eigenvector_rank(G):\n",
    "    all_nodes = set(G.nodes())\n",
    "    components = nx.algorithms.components.weakly_connected_components(G)\n",
    "    rank = dict()\n",
    "    for c in components:\n",
    "        H = G.copy()\n",
    "        H.remove_nodes_from(all_nodes - set(c))\n",
    "        component_rank = nx.algorithms.centrality.eigenvector_centrality_numpy(H)\n",
    "        rank.update(component_rank)\n",
    "    nodes, ranks = zip(*list(rank.items()))\n",
    "    rank = dict(zip(list(nodes), list(ranks)))\n",
    "    order = dict((elt[0], i) for i, elt in enumerate(sorted(rank.items(), key=lambda x: x[1])))\n",
    "    return rank, order\n",
    "\n",
    "def get_pagerank(G):\n",
    "    rank = nx.pagerank(G)\n",
    "    order = dict((elt[0], i) for i, elt in enumerate(sorted(rank.items(), key=lambda x: x[1])))\n",
    "    return rank, order\n",
    "\n",
    "def count_violations(G, order):\n",
    "    rank_differences = []\n",
    "    violations = 0\n",
    "    for v, w in G.edges():\n",
    "        difference = order[w] - order[v]\n",
    "        rank_differences.append(difference)\n",
    "        if difference < 0:\n",
    "            violations += 1\n",
    "    return rank_differences, violations\n",
    "    \n",
    "def plot_ordering(G, rank, title=\"Ordering\", scale=150, shape=\"dot\"):\n",
    "    nodes = list(G.nodes())\n",
    "    pos = dict((v, (0, r*scale)) for v, r in unit(rank).items())\n",
    "    return visualize_visjs(G, layout=None, smooth=True, pos=pos, scale=scale, title=title, node_alpha=0.5, shape=shape)\n",
    "\n",
    "def plot_orderings(Gs, ranks, title=\"Ordering\", connect=False, scale=150, shape=\"dot\", node_alpha=0.5):\n",
    "    pos = dict()\n",
    "    H = nx.DiGraph()\n",
    "    all_nodes = set()\n",
    "    for G in Gs:\n",
    "        all_nodes |= set(G.nodes())\n",
    "    for i, rank in enumerate(ranks):\n",
    "        rank = unit(rank)\n",
    "        GG = Gs[i]\n",
    "        GG.add_nodes_from(all_nodes)\n",
    "        new_labels = dict((v, \"{}-{}\".format(v, i)) for v in all_nodes)\n",
    "        GG = nx.relabel.relabel_nodes(GG, new_labels)\n",
    "        # Reverse y axis so higher rank is up\n",
    "        pos_i = dict((new_labels[v], (i*scale, -1*r*scale)) for v, r in rank.items())\n",
    "        pos.update(pos_i)\n",
    "        H = nx.compose(H, GG)\n",
    "    if connect:\n",
    "        for i in range(len(ranks) - 1):\n",
    "            for v in nodes:\n",
    "                H.add_edge(\"{}-{}\".format(v, i), \"{}-{}\".format(v, i+1))\n",
    "    return visualize_visjs(H, layout=None, smooth=True, pos=pos, scale=scale, title=title, shape=shape, node_alpha=node_alpha, shadow=False)\n",
    "\n",
    "def mvr_example():\n",
    "    H = nx.DiGraph()\n",
    "    H.add_edges_from([\n",
    "        ('Lemon', 'Cotton'),\n",
    "        ('Mia', 'Cotton'),\n",
    "        ('Mia', 'Lemon'),\n",
    "        ('Mia', 'Bagel'),\n",
    "        ('Lemon', 'Bagel'),\n",
    "        ('Setzer', 'Cotton'),\n",
    "        ('Lemon', 'Setzer')\n",
    "    ])\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, visualize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = mvr_example()\n",
    "visualize_visjs(H, shape=\"cat\", scale = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define an ordering, visualize it, and count the number of violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To re-order the nodes, change these numbers\n",
    "mvr_order = {\n",
    "    \"Bagel\":  0,\n",
    "    \"Cotton\": 1,\n",
    "    \"Lemon\":  2,\n",
    "    \"Mia\":    3,\n",
    "    \"Setzer\": 4\n",
    "}\n",
    "# Count the violations and visualize\n",
    "rank_differences, violations = count_violations(H, mvr_order)\n",
    "print(\"Violations:\", violations)\n",
    "plot_ordering(H, mvr_order, scale=500, shape=\"cat\", title=\"MVR Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which edges count as violations? What is the lowest number of violations you can find? It might be helpful to move the nodes in the visualization. Try re-running the above cell after changing the rank numbers for each node. When you're done, run the cell below to compare your results to the minimum violation ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvr_score, mvr_order = get_mvr_rank(H)\n",
    "for label, rank in sorted(mvr_order.items(), key=lambda x: x[1]):\n",
    "    print(\"Place {}: {}\".format(rank, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network above has a ranking with no violations. However, in real networks, it is uncommon to have a ranking with no violations, which is why the _minimum_ violation ranking is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teenage Friendship and Lifestyle Study\n",
    "### Load and visualize the social network\n",
    "Now we'll load and visualize friendship data from a real social network. The [MA1997] study determined friendships by asking participants to name their top friends. This method has in interesting feature: it is possible for a participant to list someone as a friend who does not list the participant as a friend. The friendship ties are _directed_. In the visualization, arrows go from the participant to the individuals they named as friends. Reciprocated friendships have arrows on both ends.\n",
    "\n",
    "Study participants were asked to name up to 12 friends. Friends who were not study participants were not recorded. What are the benefits and drawbacks of this method of eliciting social networks? Can you think of another way to determine the friendship network of a group of people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = load_tfls()\n",
    "visualize_visjs(G, scale=1000, title=\"Full Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Violation Ranking for TFLS\n",
    "Now let's try to find the minimum violation ranking for the Teen Friendship and Lifestyle Study. The data set is much larger than the previous example, so it may take longer to run. If it takes longer than one minute to find an MVR, the function will exit with an error message. If the time limit is reached, use the data in the error message to calculate how long it would have taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mvr_score, mvr_order = get_mvr_rank(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MVRs\n",
    "\n",
    "We'd like to find the MVR. Unfortunately, as we've seen above, finding the MVR is very difficult even with a lot of computing power (in computer science terms, it's NP-hard).\n",
    "Several apporoximate methods exist.\n",
    "\n",
    "The example below explores some possible approximations. Eigenvector centrality gives nodes a score based on how well-connected they are to other highly-connected nodes. PageRank (used by Google's search engine) is similar to eigenvector centrality, but is designed to handle disconnected networks. SpringRank [BLN2013] is specifically designed to find approximate MVRs. Each assigns a score to nodes, and then nodes are ranked according to that value. The visualization below shows (from left to right) eigenvector centrality, PageRank, and SpringRank. Higher nodes have higher scores, and arrows pointing downward represent violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the rank\n",
    "er_score, er_order = get_eigenvector_rank(G)\n",
    "sr_score, sr_order = get_spring_rank(G)\n",
    "pr_score, pr_order = get_pagerank(G)\n",
    "# Plot the orderings\n",
    "plot_orderings([G, G, G], [er_score, pr_score, sr_score], title=\"MVR Examples\", scale=2000, node_alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare approximations\n",
    "\n",
    "The cells below count violations for rankings based on eigenvector centrality and SpringRank. Which works better? SpringRank is specifically designed to approximate MVRs, while eigenvector is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_differences, er_violations = count_violations(G, er_order)\n",
    "print(\"Violations:\", er_violations)\n",
    "print(\"Violation percent:\", er_violations / len(list(G.edges())))\n",
    "print(\"Mean rank difference:\", np.mean(er_differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_differences, pr_violations = count_violations(G, pr_order)\n",
    "print(\"Violations:\", pr_violations)\n",
    "print(\"Violation percent:\", pr_violations / len(list(G.edges())))\n",
    "print(\"Mean rank difference:\", np.mean(pr_differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SpringRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_differences, sr_violations = count_violations(G, sr_order)\n",
    "print(\"Violations:\", sr_violations)\n",
    "print(\"Violation percent:\", sr_violations / len(list(G.edges())))\n",
    "print(\"Mean rank difference:\", np.mean(sr_differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how highly correlated different scoring methods are. Each row/column below represents one scoring method. The off-diagonal squares plot different methods against each other, while the diagonals show histograms for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Eigenvector\": er_score,\n",
    "    \"PageRank\": pr_score,\n",
    "    \"SpringRank\": sr_score\n",
    "})\n",
    "df[\"Eigenvector\"] = np.log10(df[\"Eigenvector\"])\n",
    "df[\"PageRank\"] = np.log10(df[\"PageRank\"])\n",
    "pd.plotting.scatter_matrix(df, figsize=(12,12))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, select one of the scoring methods to use for the rest of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method = \"Eigenvector\"\n",
    "method = \"PageRank\"\n",
    "#method = \"SpringRank\"\n",
    "\n",
    "if method == \"Eigenvector\":\n",
    "    rank_differences, violations, get_rank = er_differences, er_violations, get_eigenvector_rank\n",
    "elif method == \"PageRank\":\n",
    "    rank_differences, violations, get_rank = pr_differences, pr_violations, get_pagerank\n",
    "elif method == \"SpringRank\":\n",
    "    rank_differences, violations, get_rank = sr_differences, sr_violations, get_spring_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(min(rank_differences) - 0.5, max(rank_differences) + 0.5)\n",
    "plt.hist(rank_differences, bins=bins)\n",
    "xlabel(\"Rank difference\"); ylabel(\"Count\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def gradient(x):\n",
    "    y = math.floor(128 - x*64)\n",
    "    b = math.floor(128 + x*64)\n",
    "    return \"{},{},{}\".format(y, y, b)\n",
    "\n",
    "def plot_ordering_evolution(Gs, ranks, title=\"Ordering\", scale=150, shape=\"dot\", node_alpha=0.5):\n",
    "    pos = dict()\n",
    "    H = nx.DiGraph()\n",
    "    all_nodes = set()\n",
    "    node_colors = {}\n",
    "    edge_colors = {}\n",
    "    for i, rank in enumerate(ranks):\n",
    "        ranks[i] = unit(rank)\n",
    "    for G in Gs:\n",
    "        all_nodes |= set(G.nodes())\n",
    "    for i, rank in enumerate(ranks):\n",
    "        GG = Gs[i].copy()\n",
    "        GG.remove_edges_from(list(GG.edges()))\n",
    "        GG.add_nodes_from(all_nodes)\n",
    "        new_labels = dict((v, \"{}-{}\".format(v, i)) for v in all_nodes)\n",
    "        GG = nx.relabel.relabel_nodes(GG, new_labels)\n",
    "        pos_i = dict((new_labels[v], (i*scale, r*scale)) for v, r in rank.items())\n",
    "        pos.update(pos_i)\n",
    "        H = nx.compose(H, GG)\n",
    "    for i in range(1, len(ranks)):\n",
    "        for v, new_rank in ranks[i].items():\n",
    "            # Calculate change and scale to (-1, 1)\n",
    "            old_label = \"{}-{}\".format(v, i-1)\n",
    "            label = \"{}-{}\".format(v, i)\n",
    "            delta = (new_rank - ranks[i-1][v]) / 2.0\n",
    "            color = gradient(delta)\n",
    "            node_colors[label] = color\n",
    "            if old_label in H and label in H:\n",
    "                H.add_edge(old_label, label)\n",
    "                edge_colors[(old_label, label)] = color\n",
    "    return visualize_visjs(\n",
    "        H, scale=scale, layout=None, pos=pos,\n",
    "        shape=shape, node_colors=node_colors, node_alpha=node_alpha, shadow=False,\n",
    "        edge_colors=edge_colors,\n",
    "        title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_t = []\n",
    "order_t = []\n",
    "G = []\n",
    "all_nodes = set()\n",
    "for wave in range(3):\n",
    "    G.append(load_tfls(wave+1))\n",
    "    all_nodes |= set(G[wave].nodes())\n",
    "for wave in range(3):\n",
    "    G[wave].add_nodes_from(all_nodes)\n",
    "    r, o = get_rank(G[wave])\n",
    "    score_t.append(r)\n",
    "    order_t.append(o)\n",
    "# Plot the orderings\n",
    "plot_ordering_evolution(G, score_t, title=\"Rank Over Time\", scale=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_tfls_behavior():\n",
    "    # Load alcohol data\n",
    "    alc = pd.read_csv(\"external/TFLS/alcohol.csv\").set_index(\"Unnamed: 0\")\n",
    "    alc = alc.rename(columns={\"t1\": \"alcohol1\", \"t2\": \"alcohol2\", \"t3\": \"alcohol3\"})\n",
    "    df = alc\n",
    "    # Load age data\n",
    "    x = pd.read_csv(\"external/TFLS/age.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"x\": \"age\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Load sex data\n",
    "    x = pd.read_csv(\"external/TFLS/sex.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"x\": \"sex\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Load cannabis data\n",
    "    x = pd.read_csv(\"external/TFLS/cannabis.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"t1\": \"cannabis1\", \"t2\": \"cannabis2\", \"t3\": \"cannabis3\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Load money data\n",
    "    x = pd.read_csv(\"external/TFLS/money.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"t1\": \"money1\", \"t2\": \"money2\", \"t3\": \"money3\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Load romantic data\n",
    "    x = pd.read_csv(\"external/TFLS/romantic.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"t1\": \"romantic1\", \"t2\": \"romantic2\", \"t3\": \"romantic3\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Load tobacco data\n",
    "    x = pd.read_csv(\"external/TFLS/tobacco.csv\").set_index(\"Unnamed: 0\")\n",
    "    x = x.rename(columns={\"t1\": \"tobacco1\", \"t2\": \"tobacco2\", \"t3\": \"tobacco3\"})\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    # Set name of index\n",
    "    df[\"participant\"] = df.index\n",
    "    df = df.set_index(\"participant\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = load_tfls_behavior()\n",
    "df = pd.concat([\n",
    "    behavior[\"age\"],\n",
    "    behavior[\"sex\"],\n",
    "    behavior[\"tobacco1\"],\n",
    "    behavior[\"cannabis1\"],\n",
    "    behavior[\"alcohol1\"],\n",
    "    behavior[\"money1\"],\n",
    "    behavior[\"romantic1\"]\n",
    "    ], axis=1\n",
    ")\n",
    "sr = pd.DataFrame.from_dict(sr_rank, orient=\"index\")\n",
    "sr[\"participant\"] = sr.index\n",
    "sr = sr.set_index(\"participant\")\n",
    "sr = sr.rename(columns={0: \"spring_rank\"})\n",
    "df = pd.concat([df, sr], axis=1)\n",
    "pd.plotting.scatter_matrix(df, figsize=(12,12))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[BLN2013] De Bacco, C., Larremore, D. B., & Moore, C. (2017). A physical model for efficient ranking in networks. arXiv preprint arXiv:1709.09002.\n",
    "\n",
    "[MA1997] L. Michell, and A. Amos, \"Girls, pecking order and smoking.\" Social Science & Medicine 44(12), 1861-1869 (1997)\n",
    "\n",
    "[KONECT2017] Facebook wall posts network dataset -- KONECT, April 2017.\n",
    "\n",
    "[VMCG2009] Bimal Viswanath, Alan Mislove, Meeyoung Cha, and Krishna P. Gummadi. On the evolution of user interaction in Facebook. In Proc. Workshop on Online Social Networks, pages 37--42, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
